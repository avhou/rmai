@misc{bloiceAugmentorImageAugmentation2017,
  title = {Augmentor: {{An Image Augmentation Library}} for {{Machine Learning}}},
  shorttitle = {Augmentor},
  author = {Bloice, Marcus D. and Stocker, Christof and Holzinger, Andreas},
  year = {2017},
  month = aug,
  number = {arXiv:1708.04680},
  eprint = {1708.04680},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1708.04680},
  urldate = {2023-10-23},
  abstract = {The generation of artificial data based on existing observations, known as data augmentation, is a technique used in machine learning to improve model accuracy, generalisation, and to control overfitting. Augmentor is a software package, available in both Python and Julia versions, that provides a high level API for the expansion of image data using a stochastic, pipeline-based approach which effectively allows for images to be sampled from a distribution of augmented images at runtime. Augmentor provides methods for most standard augmentation practices as well as several advanced features such as label-preserving, randomised elastic distortions, and provides many helper functions for typical augmentation tasks used in machine learning.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Data Augmentation Implementation,Statistics - Machine Learning},
  file = {C\:\\Users\\u0129016\\Zotero\\storage\\JXVFJCB2\\Bloice et al. - 2017 - Augmentor An Image Augmentation Library for Machi.pdf;C\:\\Users\\u0129016\\Zotero\\storage\\RA2WP66U\\1708.html}
}

@inproceedings{daoKernelTheoryModern2019,
  title = {A {{Kernel Theory}} of {{Modern Data Augmentation}}},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Dao, Tri and Gu, Albert and Ratner, Alexander and Smith, Virginia and Sa, Chris De and Re, Christopher},
  year = {2019},
  month = may,
  pages = {1528--1537},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2023-10-26},
  abstract = {Data augmentation, a technique in which a training set is expanded with class-preserving transformations, is ubiquitous in modern machine learning pipelines. In this paper, we seek to establish a theoretical framework for understanding data augmentation. We approach this from two directions: First, we provide a general model of augmentation as a Markov process, and show that kernels appear naturally with respect to this model, even when we do not employ kernel classification. Next, we analyze more directly the effect of augmentation on kernel classifiers, showing that data augmentation can be approximated by first-order feature averaging and second-order variance regularization components. These frameworks both serve to illustrate the ways in which data augmentation affects the downstream learning model, and the resulting analyses provide novel connections between prior work in invariant kernels, tangent propagation, and robust optimization. Finally, we provide several proof-of-concept applications showing that our theory can be useful for accelerating machine learning workflows, such as reducing the amount of computation needed to train using augmented data, and predicting the utility of a transformation prior to training.},
  langid = {english},
  keywords = {Data Augmentation Theory},
  file = {C:\Users\u0129016\Zotero\storage\YW6K65PM\Dao et al. - 2019 - A Kernel Theory of Modern Data Augmentation.pdf}
}

@article{humayunTrafficManagementMultiScale2022,
  title = {Traffic {{Management}}: {{Multi-Scale Vehicle Detection}} in {{Varying Weather Conditions Using YOLOv4}} and {{Spatial Pyramid Pooling Network}}},
  shorttitle = {Traffic {{Management}}},
  author = {Humayun, Mamoona and Ashfaq, Farzeen and Jhanjhi, Noor Zaman and Alsadun, Marwah Khalid},
  year = {2022},
  month = jan,
  journal = {Electronics},
  volume = {11},
  number = {17},
  pages = {2748},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2079-9292},
  doi = {10.3390/electronics11172748},
  urldate = {2023-10-23},
  abstract = {Detecting and counting on road vehicles is a key task in intelligent transport management and surveillance systems. The applicability lies both in urban and highway traffic monitoring and control, particularly in difficult weather and traffic conditions. In the past, the task has been performed through data acquired from sensors and conventional image processing toolbox. However, with the advent of emerging deep learning based smart computer vision systems the task has become computationally efficient and reliable. The data acquired from road mounted surveillance cameras can be used to train models which can detect and track on road vehicles for smart traffic analysis and handling problems such as traffic congestion particularly in harsh weather conditions where there are poor visibility issues because of low illumination and blurring. Different vehicle detection algorithms focusing the same issue deal only with on or two specific conditions. In this research, we address detecting vehicles in a scene in multiple weather scenarios including haze, dust and sandstorms, snowy and rainy weather both in day and nighttime. The proposed architecture uses CSPDarknet53 as baseline architecture modified with spatial pyramid pooling (SPP-NET) layer and reduced Batch Normalization layers. We also augment the DAWN Dataset with different techniques including Hue, Saturation, Exposure, Brightness, Darkness, Blur and Noise. This not only increases the size of the dataset but also make the detection more challenging. The model obtained mean average precision of 81\% during training and detected smallest vehicle present in the image},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {artificial intelligence,deep learning,intelligent traffic monitoring,traffic surveillance,urban and highway traffic analysis,vehicle detection},
  file = {C:\Users\u0129016\Zotero\storage\Q37UWSUR\Humayun et al. - 2022 - Traffic Management Multi-Scale Vehicle Detection .pdf}
}

@article{kumarObjectDetectionAdverse2023,
  title = {Object {{Detection}} in {{Adverse Weather}} for {{Autonomous Driving}} through {{Data Merging}} and {{YOLOv8}}},
  author = {Kumar, Debasis and Muhammad, Naveed},
  year = {2023},
  journal = {Sensors (Basel, Switzerland)},
  volume = {23},
  number = {20},
  pages = {8471-},
  issn = {1424-8220},
  doi = {10.3390/s23208471},
  abstract = {For autonomous driving, perception is a primary and essential element that fundamentally deals with the insight into the ego vehicle's environment through sensors. Perception is challenging, wherein it suffers from dynamic objects and continuous environmental changes. The issue grows worse due to interrupting the quality of perception via adverse weather such as snow, rain, fog, night light, sand storms, strong daylight, etc. In this work, we have tried to improve camera-based perception accuracy, such as autonomous-driving-related object detection in adverse weather. We proposed the improvement of YOLOv8-based object detection in adverse weather through transfer learning using merged data from various harsh weather datasets. Two prosperous open-source datasets (ACDC and DAWN) and their merged dataset were used to detect primary objects on the road in harsh weather. A set of training weights was collected from training on the individual datasets, their merged versions, and several subsets of those datasets according to their characteristics. A comparison between the training weights also occurred by evaluating the detection performance on the datasets mentioned earlier and their subsets. The evaluation revealed that using custom datasets for training significantly improved the detection performance compared to the YOLOv8 base weights. Furthermore, using more images through the feature-related data merging technique steadily increased the object detection performance.},
  langid = {english},
  keywords = {Data Augmentation Application},
  file = {C:\Users\u0129016\Zotero\storage\L65P4CXH\Kumar and Muhammad - 2023 - Object Detection in Adverse Weather for Autonomous.pdf}
}

@article{liVehicleDetectionFoggy2022,
  title = {Vehicle Detection in Foggy Weather Based on an Enhanced {{YOLO}} Method},
  author = {Li, Wei},
  year = {2022},
  month = jun,
  journal = {Journal of Physics: Conference Series},
  volume = {2284},
  number = {1},
  pages = {012015},
  issn = {1742-6588, 1742-6596},
  doi = {10.1088/1742-6596/2284/1/012015},
  urldate = {2023-09-23},
  abstract = {Vehicle detection is the key to driverless technology. For safety, driverless technology requires extremely high accuracy and real-time for vehicle detection in different situations. In this paper, we study an enhanced YOLO -based algorithm for vehicle detection in foggy weather conditions. We add a dehazing module in the YOLO model for more information restoration, which is built by the multi-scale retinex with color restoration (MSRCR). And the enhanced model is trained with the augmentation data processed MSRCR for more stable performance. We evaluate our method in the public dataset, the results show the enhanced YOLO model has better performance than conventional YOLO in vehicle detection in foggy weather.},
  langid = {english},
  file = {C:\Users\u0129016\Zotero\storage\NV3UWSBG\Li - 2022 - Vehicle detection in foggy weather based on an enh.pdf}
}

@misc{perezEffectivenessDataAugmentation2017,
  title = {The {{Effectiveness}} of {{Data Augmentation}} in {{Image Classification}} Using {{Deep Learning}}},
  author = {Perez, Luis and Wang, Jason},
  year = {2017},
  month = dec,
  number = {arXiv:1712.04621},
  eprint = {1712.04621},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1712.04621},
  urldate = {2023-10-23},
  abstract = {In this paper, we explore and compare multiple solutions to the problem of data augmentation in image classification. Previous work has demonstrated the effectiveness of data augmentation through simple techniques, such as cropping, rotating, and flipping input images. We artificially constrain our access to data to a small subset of the ImageNet dataset, and compare each data augmentation technique in turn. One of the more successful data augmentations strategies is the traditional transformations mentioned above. We also experiment with GANs to generate images of different styles. Finally, we propose a method to allow a neural net to learn augmentations that best improve the classifier, which we call neural augmentation. We discuss the successes and shortcomings of this method on various datasets.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Data Augmentation Implementation,Data Augmentation Theory},
  file = {C\:\\Users\\u0129016\\Zotero\\storage\\2S8NA8UJ\\Perez and Wang - 2017 - The Effectiveness of Data Augmentation in Image Cl.pdf;C\:\\Users\\u0129016\\Zotero\\storage\\RCCNR86M\\1712.html}
}

@article{shortenSurveyImageData2019,
  title = {A Survey on {{Image Data Augmentation}} for {{Deep Learning}}},
  author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
  year = {2019},
  month = dec,
  journal = {Journal of Big Data},
  volume = {6},
  number = {1},
  pages = {60},
  issn = {2196-1115},
  doi = {10.1186/s40537-019-0197-0},
  urldate = {2023-10-27},
  abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
  langid = {english},
  keywords = {Data Augmentation Implementation,Data Augmentation Theory},
  file = {C:\Users\u0129016\Zotero\storage\VKGFSREN\Shorten and Khoshgoftaar - 2019 - A survey on Image Data Augmentation for Deep Learn.pdf}
}

@article{songVisionbasedVehicleDetection2019,
  title = {Vision-Based Vehicle Detection and Counting System Using Deep Learning in Highway Scenes},
  author = {Song, Huansheng and Liang, Haoxiang and Li, Huaiyu and Dai, Zhe and Yun, Xu},
  year = {2019},
  month = dec,
  journal = {European Transport Research Review},
  volume = {11},
  number = {1},
  pages = {51},
  issn = {1866-8887},
  doi = {10.1186/s12544-019-0390-4},
  urldate = {2023-10-28},
  abstract = {Intelligent vehicle detection and counting are becoming increasingly important in the field of highway management. However, due to the different sizes of vehicles, their detection remains a challenge that directly affects the accuracy of vehicle counts. To address this issue, this paper proposes a vision-based vehicle detection and counting system. A new high definition highway vehicle dataset with a total of 57,290 annotated instances in 11,129 images is published in this study. Compared with the existing public datasets, the proposed dataset contains annotated tiny objects in the image, which provides the complete data foundation for vehicle detection based on deep learning. In the proposed vehicle detection and counting system, the highway road surface in the image is first extracted and divided into a remote area and a proximal area by a newly proposed segmentation method; the method is crucial for improving vehicle detection. Then, the above two areas are placed into the YOLOv3 network to detect the type and location of the vehicle. Finally, the vehicle trajectories are obtained by the ORB algorithm, which can be used to judge the driving direction of the vehicle and obtain the number of different vehicles. Several highway surveillance videos based on different scenes are used to verify the proposed methods. The experimental results verify that using the proposed segmentation method can provide higher detection accuracy, especially for the detection of small vehicle objects. Moreover, the novel strategy described in this article performs notably well in judging driving direction and counting vehicles. This paper has general practical significance for the management and control of highway scenes.},
  keywords = {Highway management,Image segmentation,Vehicle counting,Vehicle dataset,Vehicle detection},
  file = {C\:\\Users\\u0129016\\Zotero\\storage\\SAWVYBNR\\Song et al. - 2019 - Vision-based vehicle detection and counting system.pdf;C\:\\Users\\u0129016\\Zotero\\storage\\3BH4B72G\\s12544-019-0390-4.html}
}

@article{stralenInfluenceAdverseWeather2015,
  title = {The Influence of Adverse Weather Conditions on Probability of Congestion on Dutch Motorways},
  author = {Stralen, Wouter J. H. and Calvert, Simeon C. and Molin, Eric J. E.},
  year = {2015},
  journal = {European Journal of Transport and Infrastructure Research},
  volume = {15},
  number = {4},
  publisher = {{Editorial Board EJTIR}},
  issn = {1567-7141},
  doi = {10.18757/ejtir.2015.15.4.3093},
  abstract = {Weather conditions are widely acknowledged to contribute to the occurrence of congestion on motorway traffic by influencing both traffic supply and traffic demand. To the best of our knowledge, this is the first paper that explicitly integrates supply and demand effects in predicting the influence of adverse weather conditions on the probability of occurrence of congestion. Traffic demand is examined by conducting a stated adaptation experiment, in which changes in travel choices are observed under adverse weather scenarios. Based on these choices, a Panel Mixed Logit model is estimated. Supply effects are taken into account by examining the influence of precipitation on motorway capacity. Based on the Product Limit Method, capacity distribution functions are estimated for dry weather, light rain and heavy rain. With the developed model to integrate the supply and demand effects breakdown probabilities can be calculated for any given traffic demand and capacity. The results show that rainfall leads to a significant increase in the probability of traffic breakdown at bottleneck locations. Interestingly the probability of a breakdown at these bottleneck locations is predicted to be slightly higher in light rain (98.7\%) than in heavy rain (95.7\%) conditions, which is the result of the higher traffic demand in light rain conditions. Based on the results presented in this paper, it can be recommended to always incorporate both supply and demand effects in the predictions of motorway breakdown probabilities due to adverse weather conditions to improve the validity of the predictions. \textcopyright{} 2015 Editorial Board EJTIR. All rights reserved.},
  langid = {english},
  keywords = {adverse weather conditions,Breakdown probability,Distribution functions,Earth,Life,Meteorology,Mobility,modal shift,motorway capacity,motorway congestion probability,motorway traffic dem,Probability,Rain,Reliable Mobility Systems,Smart Mobility,SMb,Social Sciences,Traffic,Traffic breakdown,Traffic congestion,Traffic control,Transportation engineering,Urban Mobility \& Environment}
}

@article{xuComprehensiveSurveyImage2023,
  title = {A {{Comprehensive Survey}} of {{Image Augmentation Techniques}} for {{Deep Learning}}},
  author = {Xu, Mingle and Yoon, Sook and Fuentes, Alvaro and Park, Dong Sun},
  year = {2023},
  month = may,
  journal = {Pattern Recognition},
  volume = {137},
  pages = {109347},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2023.109347},
  urldate = {2023-10-23},
  abstract = {Although deep learning has achieved satisfactory performance in computer vision, a large volume of images is required. However, collecting images is often expensive and challenging. Many image augmentation algorithms have been proposed to alleviate this issue. Understanding existing algorithms is, therefore, essential for finding suitable and developing novel methods for a given task. In this study, we perform a comprehensive survey of image augmentation for deep learning using a novel informative taxonomy. To examine the basic objective of image augmentation, we introduce challenges in computer vision tasks and vicinity distribution. The algorithms are then classified among three categories: model-free, model-based, and optimizing policy-based. The model-free category employs the methods from image processing, whereas the model-based approach leverages image generation models to synthesize images. In contrast, the optimizing policy-based approach aims to find an optimal combination of operations. Based on this analysis, we believe that our survey enhances the understanding necessary for choosing suitable methods and designing novel algorithms.},
  keywords = {Computer vision,Data augmentation,Deep learning,Image augmentation,Image variation,Survey,Vicinity distribution},
  file = {C\:\\Users\\u0129016\\Zotero\\storage\\QGAXH3AQ\\Xu et al. - 2023 - A Comprehensive Survey of Image Augmentation Techn.pdf;C\:\\Users\\u0129016\\Zotero\\storage\\IUZQAZWM\\S0031320323000481.html}
}

@data{bw1x-yh39-20,
  doi = {10.21227/bw1x-yh39},
  url = {https://dx.doi.org/10.21227/bw1x-yh39},
  author = {A. KENK, Mourad and Hassaballah, Mahmoud},
  publisher = {IEEE Dataport},
  title = {DAWN: Vehicle Detection in Adverse Weather Nature},
  year = {2020} 
}

@article{CVIU_UA-DETRAC,
  author = {Longyin Wen and Dawei Du and Zhaowei Cai and Zhen Lei and Ming{-}Ching Chang and
Honggang Qi and Jongwoo Lim and Ming{-}Hsuan Yang and Siwei Lyu},
  title = { {UA-DETRAC:} {A} New Benchmark and Protocol for Multi-Object Detection and Tracking},
  journal = {Computer Vision and Image Understanding},
  year = {2020}
}

@misc{linMicrosoftCOCOCommon2015a,
  title = {Microsoft {{COCO}}: {{Common Objects}} in {{Context}}},
  shorttitle = {Microsoft {{COCO}}},
  author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Doll{\'a}r, Piotr},
  year = {2015},
  month = feb,
  number = {arXiv:1405.0312},
  eprint = {1405.0312},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1405.0312},
  urldate = {2023-10-29},
  abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\u0129016\\Zotero\\storage\\TZ9XBLA6\\Lin et al. - 2015 - Microsoft COCO Common Objects in Context.pdf;C\:\\Users\\u0129016\\Zotero\\storage\\LK82ZMHB\\1405.html}
}

@software{yolov8_ultralytics,
  author = {Glenn Jocher and Ayush Chaurasia and Jing Qiu},
  title = {Ultralytics YOLOv8},
  version = {8.0.0},
  year = {2023},
  url = {https://github.com/ultralytics/ultralytics},
  orcid = {0000-0001-5950-6979, 0000-0002-7603-6750, 0000-0003-3783-7069},
  license = {AGPL-3.0}
}

@software{imgaug,
  author = {Alexander B. Jung},
  title = {{imgaug}},
  version = {0.4.0},
  url = {https://github.com/aleju/imgaug},
  year = {2020}
}